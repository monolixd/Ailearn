{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monolixd/Ailearn/blob/main/Tf_ANDpytorchBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2af5d5-866d-4356-b993-897c896c377c",
      "metadata": {
        "id": "3f2af5d5-866d-4356-b993-897c896c377c"
      },
      "source": [
        "## สร้างโมเดล Deep Learning ด้วย TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c47c33f-80e2-4a61-a136-f5f89c363af4",
      "metadata": {
        "id": "2c47c33f-80e2-4a61-a136-f5f89c363af4"
      },
      "source": [
        "### 1. เริ่มต้นโปรเจกต์ใน Jupyter Lab\n",
        "สร้างไฟล์ Notebook ชื่อ TensorFlow_Model.ipynb แล้วเขียนโค้ดตามนี้:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c637a5-9b43-4f58-a917-79d6de90f73e",
      "metadata": {
        "id": "52c637a5-9b43-4f58-a917-79d6de90f73e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f406c384-03f5-4adf-a589-4a988b53fe3c",
      "metadata": {
        "id": "f406c384-03f5-4adf-a589-4a988b53fe3c"
      },
      "source": [
        "ทำไมต้อง Import Libraries เหล่านี้?\n",
        "\n",
        "tensorflow: ใช้สร้างโมเดล Deep Learning<br>\n",
        "Sequential: ช่วยสร้างโมเดลแบบเรียงลำดับ (Sequential Model)<br>\n",
        "Dense และ Flatten: ใช้เพิ่มเลเยอร์ของโมเดล<br>\n",
        "mnist: ใช้โหลดชุดข้อมูล MNIST สำหรับการทดลอง<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde61b9c-5a79-42da-a19b-9cc0bb0ff54e",
      "metadata": {
        "id": "cde61b9c-5a79-42da-a19b-9cc0bb0ff54e"
      },
      "source": [
        "### 2. โหลดและเตรียมข้อมูล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e11564-73ad-42e2-b602-08e370a31448",
      "metadata": {
        "id": "15e11564-73ad-42e2-b602-08e370a31448",
        "outputId": "64635421-8e3a-4b8d-f8ad-73b8a5409d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 9s 1us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalization: ปรับค่าพิกเซลให้อยู่ในช่วง [0, 1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c046a3a5-ea2f-49c6-8be5-ee286997567b",
      "metadata": {
        "id": "c046a3a5-ea2f-49c6-8be5-ee286997567b"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "mnist.load_data(): โหลดข้อมูลภาพตัวเลข (0-9) ขนาด 28x28<br>\n",
        "Normalization: ช่วยให้การเรียนรู้ของโมเดลเร็วขึ้น เพราะค่าข้อมูลอยู่ในช่วง [0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2271da9-1563-4e94-81ac-eaa9b6d0b46e",
      "metadata": {
        "id": "c2271da9-1563-4e94-81ac-eaa9b6d0b46e"
      },
      "source": [
        "### 3. สร้างโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a08aeb-fbd0-4902-90ff-0ecad90e0b21",
      "metadata": {
        "id": "65a08aeb-fbd0-4902-90ff-0ecad90e0b21"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # แปลงภาพ 28x28 เป็นเวกเตอร์\n",
        "    Dense(128, activation='relu'), # เลเยอร์ซ่อนพร้อม ReLU Activation\n",
        "    Dense(10, activation='softmax') # เลเยอร์ Output สำหรับ 10 คลาส\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be328fb9-ac4e-4e88-b51a-006a8e34f896",
      "metadata": {
        "id": "be328fb9-ac4e-4e88-b51a-006a8e34f896"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "Flatten: แปลงภาพ 2D ให้เป็นเวกเตอร์ 1D<br>\n",
        "Dense(128, activation='relu'):<br>\n",
        "เพิ่มเลเยอร์ซ่อนขนาด 128 นิวรอน<br>\n",
        "ReLU: แก้ปัญหา Gradient Vanishing<br><br>\n",
        "Dense(10, activation='softmax'):<br>\n",
        "ใช้สำหรับการจำแนกคลาส"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb31e7d4-0537-4ba1-a7ba-79dd3eafbe85",
      "metadata": {
        "id": "bb31e7d4-0537-4ba1-a7ba-79dd3eafbe85"
      },
      "source": [
        "### 4. คอมไพล์โมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3f455e-d1f4-4320-b6f8-e29db9c4dd21",
      "metadata": {
        "id": "bc3f455e-d1f4-4320-b6f8-e29db9c4dd21"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c2f389d-d1b5-44cb-a094-0c9ccc3b61ce",
      "metadata": {
        "id": "2c2f389d-d1b5-44cb-a094-0c9ccc3b61ce"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "adam: เป็น Optimizer ที่เร็วและปรับการเรียนรู้ได้อัตโนมัติ<br>\n",
        "sparse_categorical_crossentropy: ใช้คำนวณความผิดพลาด (Loss) สำหรับปัญหาจำแนกหลายคลาส"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5769510f-b78e-4f63-9d8b-2ee422884e79",
      "metadata": {
        "id": "5769510f-b78e-4f63-9d8b-2ee422884e79"
      },
      "source": [
        "### 5. ฝึกโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563dd4f0-160e-47fa-964d-5718ee759256",
      "metadata": {
        "id": "563dd4f0-160e-47fa-964d-5718ee759256",
        "outputId": "bc946c49-8996-4a0f-fd10-8027fe1f8c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2631 - accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1147 - accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0783 - accuracy: 0.9764\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0582 - accuracy: 0.9814\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0451 - accuracy: 0.9859\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1fe4ac68a60>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5015b9a-63a6-422a-bdc1-a4615c90cd86",
      "metadata": {
        "id": "e5015b9a-63a6-422a-bdc1-a4615c90cd86"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "epochs=5: โมเดลจะเรียนรู้ข้อมูลทั้งหมด 5 รอบ<br>\n",
        "batch_size=32: แบ่งข้อมูลเป็นกลุ่มละ 32 ตัวอย่างในแต่ละรอบ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de26d426-0a21-4dd7-9c29-7efe207e16aa",
      "metadata": {
        "id": "de26d426-0a21-4dd7-9c29-7efe207e16aa"
      },
      "source": [
        "### 6. ทดสอบโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0ea73b-bb93-46c2-9343-9efd6b297214",
      "metadata": {
        "id": "7e0ea73b-bb93-46c2-9343-9efd6b297214",
        "outputId": "ac620399-8625-4fbe-a1e6-e56b19c5fc02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9785\n",
            "Test Accuracy: 0.9785000085830688\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b19945-4735-47f2-8ddd-8ad21e08e30d",
      "metadata": {
        "id": "85b19945-4735-47f2-8ddd-8ad21e08e30d"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "ใช้ข้อมูลทดสอบเพื่อดูความแม่นยำของโมเดล"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e281dd03-6742-4e3e-909f-1b676eb9ed81",
      "metadata": {
        "id": "e281dd03-6742-4e3e-909f-1b676eb9ed81"
      },
      "source": [
        "## สร้างโมเดล Deep Learning ด้วย PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328b7371-43b2-431f-bb2d-a5784dbd637b",
      "metadata": {
        "id": "328b7371-43b2-431f-bb2d-a5784dbd637b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6e115a-5b65-4358-8377-a3bac5aa8bab",
      "metadata": {
        "id": "ed6e115a-5b65-4358-8377-a3bac5aa8bab"
      },
      "source": [
        "อธิบาย:\n",
        "\n",
        "torch และ torch.nn: ใช้สร้างโมเดล<br>\n",
        "datasets และ transforms: โหลดและแปลงข้อมูล<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8d6841-bb80-4f08-8f4b-2a15f728e97b",
      "metadata": {
        "id": "3c8d6841-bb80-4f08-8f4b-2a15f728e97b",
        "outputId": "8e5c042b-d0d9-44a4-84b1-9cddb93532a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:42<00:00, 231kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 52.2kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:11<00:00, 145kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.52MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f1609b-4ca1-42d4-b035-6148964e41df",
      "metadata": {
        "id": "f8f1609b-4ca1-42d4-b035-6148964e41df"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19860f49-66db-4156-8890-87d8cd88a2d2",
      "metadata": {
        "id": "19860f49-66db-4156-8890-87d8cd88a2d2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f66dd6a-7d77-4645-9e05-b26def962b7a",
      "metadata": {
        "id": "4f66dd6a-7d77-4645-9e05-b26def962b7a",
        "outputId": "0eb3d9bb-45f8-4e38-b01e-cb3b1a7eadfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.5268570184707642\n",
            "Epoch 2, Loss: 0.18245095014572144\n",
            "Epoch 3, Loss: 0.31349775195121765\n",
            "Epoch 4, Loss: 0.127091646194458\n",
            "Epoch 5, Loss: 0.025021007284522057\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef96b2bb-c4f4-4d0b-af68-f71dbcd7d702",
      "metadata": {
        "id": "ef96b2bb-c4f4-4d0b-af68-f71dbcd7d702",
        "outputId": "3400777c-b21f-4086-b694-ed759002e490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9645\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        outputs = model(x_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {correct / total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b83363-12d9-47e0-a183-335ff8eb934a",
      "metadata": {
        "id": "74b83363-12d9-47e0-a183-335ff8eb934a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}